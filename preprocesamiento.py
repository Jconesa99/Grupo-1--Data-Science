# -*- coding: utf-8 -*-
"""Preprocesamiento.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1awmNUczRXpLfy4SVv0WcB-6T1dBukxBy

# Ejercicio 🏡

## 📍 Objetivo
<br>Realizar la preparación de datos de la Encuesta anual de hogares realizada en todo el territorio de la Ciudad de Buenos Aires, Argentina en el 2019.
<br>Prácticamente vas a acondicionar el dataset para que te quede listo para buscar correlaciones o entrenar algún modelo de Machine Learning.

El dataset proviene del Open Data del Gobierno de Buenos Aires: [Encuesta anual de hogares 2019](https://data.buenosaires.gob.ar/dataset/encuesta-anual-hogares)

---
## 📍 Consigna 1
**_1) Cargamos los datos_**
- Carguen el dataset:
```
  data = pd.read_csv("encuesta-anual-hogares-2019.csv", sep=',')
```
**_2) Inspección inicial_**
- Eliminen las columnas `id` y `hijos_nacidos_vivos`

**_3) Discretización_**
- Para las siguientes columnas discreticen por igual frecuencia e igual rango.
    <br>`ingresos_familiares` con q=8
    <br>`ingreso_per_capita_familiar` con q=10

- En algunas situaciones hay ciertos elementos que se repiten al momento de discretizar, una forma de eliminar duplicados es con el argumento `duplicates='drop'`.
    <br><br>Para las siguientes columnas `ingreso_total_lab` y `ingreso_total_no_lab` consideren:
    ```
    data['ingreso_total_lab'] = pd.qcut(data['ingreso_total_lab'], q=10, duplicates='drop')
    data['ingreso_total_no_lab'] = pd.qcut(data['ingreso_total_no_lab'], q=4, duplicates='drop')
    ```

- Para la columna `edad` discreticen usando igual distancia con `bins=5`.

**_4) Preparación de datos_**
- Cambien el tipo de dato a `str` de las siguientes columnas: `comuna` y `nhogar`.
  <br>_¿Por qué hacemos esto?_ Para estas columnas el número es simplemente una connotación, para representar una comuna por ejemplo pero no hay una relación numérica entre ellos.

- _¿Qué esperas como valor en la columna `años_escolaridad`?_ Número enteros pero no siempre es así, cada entidad o empresa tiene diferentes formas de rellenar una encuesta.
    <br>Evalua lo siguiente: `data['años_escolaridad'].unique()`, vas a poder ver los valores únicos en la columna. Donde destacamos que todos son `object/string`.

- Reemplazar `Ningun año de escolaridad aprobado` por un '0'.
<br>Efectivamente por '0' y no 0, porque esta columna maneja datos tipo `object/string`.
    ```
    data['años_escolaridad'] = data['años_escolaridad'].replace('Ningun año de escolaridad aprobado', '0')
    ```

- Vamos a convertir los tipos de datos de la columna anterior `años_escolaridad` a enteros.
    <br>De manera intuitiva podríamos hacer:
    ```
    data['años_escolaridad'] = data['años_escolaridad'].astype("Int32")
    ```
    PEROOOOOOO marca un error, ¿cierto?
    
    Posiblemente muchas veces les pase que cuando hagan una _cast_ (conversión de un tipo de dato a otro) pueden llegar a tener conflictos si esa columna tienen _NaN_. Para este caso si queremos convertir los valores de la columna `años_escolaridad` de _string_ a _int_, hay que hacer un paso intermedio que es pasarlo a _float_.
    ```
    data['años_escolaridad'] = data['años_escolaridad'].astype(float).astype("Int32")
    ```

- Discreticen para la columna `años_escolaridad` por igual frecuencia e igual rango con un `q=5`

- No necesariamente siempre hay que rellenar los `NaN` en todas las columnas, porque quizás esa cantidad de `NaN` no es tan representativa para nuestro análisis. Así que podes eliminarlo para todo el dataframe o para ciertas columnas.
    ```
    # Eliminar filas que contengan NaN
    data = data.dropna(subset=['situacion_conyugal', 'sector_educativo', 'lugar_nacimiento', 'afiliacion_salud'])
    ```
- Después de eliminar filas, podes resetear el índice para que mantenga la secuencia:
    ```
    data = data.reset_index(drop=True)
    ```

- Rellenar los datos faltantes para la columna `años_escolaridad`. Primero añadan la categoría `desconocido` y luego hacen un rellenado de los datos faltantes con `desconocido`.

- Rellenar los datos faltantes para la columna `nivel_max_educativo` con `value=desconocido`

## 1) Cargamos los datos
"""

!pip install funpymodeling

import pandas as pd
from funpymodeling.exploratory import freq_tbl, status

!pip install -U gdown

# Descargar todo el contenido de la carpeta compartida
!gdown --folder "https://drive.google.com/drive/folders/1gARv-63rYN3_IcpYj0hfAjVUKcW5TVFE"

!gdown --id 1IWVNIVT1feXTfBDq2S9CdWeIrGN7AUj1 -O encuesta-anual-hogares-2019.csv

data = pd.read_csv("encuesta-anual-hogares-2019.csv", sep=',')

data

"""## 2) Inspección inicial"""

# Eliminamos las columnas id y hijos_nacidos_vivos
data = data.drop(columns=['id', 'hijos_nacidos_vivos'])

status(data)

"""## 3) Discretización
- Para las siguientes columnas discreticen por igual frecuencia e igual rango.
    <br>`ingresos_familiares` con q=8
    <br>`ingreso_per_capita_familiar` con q=10
"""

data2=data.copy()

data2['ingresos_familiares']=pd.qcut(data2['ingresos_familiares'], q=8)
data2['ingreso_per_capita_familiar']=pd.qcut(data2['ingreso_per_capita_familiar'], q=10)

data2[['ingresos_familiares','ingreso_per_capita_familiar']]

"""- En algunas situaciones hay ciertos elementos que se repiten al momento de discretizar, una forma de eliminar duplicados es con el argumento `duplicates='drop'`.
    <br><br>Para las siguientes columnas `ingreso_total_lab` y `ingreso_total_no_lab` consideren:
   

"""

data2['ingreso_total_lab'] = pd.qcut(data2['ingreso_total_lab'], q=10, duplicates='drop')
data2['ingreso_total_no_lab'] = pd.qcut(data['ingreso_total_no_lab'], q=4, duplicates='drop')

data2[['ingreso_total_lab','ingreso_total_no_lab']]

"""- Para la columna `edad` discreticen usando igual distancia con `bins=5`."""

data2['edad']=pd.cut(data2['edad'],bins=5)

data2['edad']

"""## 4) Preparación de datos

- Cambien el tipo de dato a `str` de las siguientes columnas: `comuna` y `nhogar`.
  <br>_¿Por qué hacemos esto?_ Para estas columnas el número es simplemente una connotación, para representar una comuna por ejemplo pero no hay una relación numérica entre ellos.
"""

status(data2)

data2['comuna'] = data2['comuna'].astype(str)
data2['nhogar'] = data2['nhogar'].astype(str)

status(data2)

"""- _¿Qué esperas como valor en la columna `años_escolaridad`?_ Número enteros pero no siempre es así, cada entidad o empresa tiene diferentes formas de rellenar una encuesta.
    <br>Evalua lo siguiente: `data['años_escolaridad'].unique()`, vas a poder ver los valores únicos en la columna. Donde destacamos que todos son `object/string`.

"""

data2['años_escolaridad'].unique()

"""- Reemplazar `Ningun año de escolaridad aprobado` por un '0'.
<br>Efectivamente por '0' y no 0, porque esta columna maneja datos tipo `object/string`.
    ```
    data['años_escolaridad'] = data['años_escolaridad'].replace('Ningun año de escolaridad aprobado', '0')
    ```
"""

data2['años_escolaridad'] = data2['años_escolaridad'].replace('Ningun año de escolaridad aprobado', '0')

"""- Vamos a convertir los tipos de datos de la columna anterior `años_escolaridad` a enteros.
    <br>De manera intuitiva podríamos hacer:
    ```
    data['años_escolaridad'] = data['años_escolaridad'].astype("Int32")
    ```
    PEROOOOOOO marca un error, ¿cierto?
    
    Posiblemente muchas veces les pase que cuando hagan una _cast_ (conversión de un tipo de dato a otro) pueden llegar a tener conflictos si esa columna tienen _NaN_. Para este caso si queremos convertir los valores de la columna `años_escolaridad` de _string_ a _int_, hay que hacer un paso intermedio que es pasarlo a _float_.
    ```
    data['años_escolaridad'] = data['años_escolaridad'].astype(float).astype("Int32")
    ```

"""

data2['años_escolaridad'] = data2['años_escolaridad'].astype("Int32")

data2['años_escolaridad'].unique()

"""- Discreticen para la columna `años_escolaridad` por igual frecuencia e igual rango con un `q=5`


"""

data2['años_escolaridad']=pd.qcut(data2['años_escolaridad'], q=5)

"""- No necesariamente siempre hay que rellenar los `NaN` en todas las columnas, porque quizás esa cantidad de `NaN` no es tan representativa para nuestro análisis. Así que podes eliminarlo para todo el dataframe o para ciertas columnas.
    ```
    # Eliminar filas que contengan NaN
    data = data.dropna(subset=['situacion_conyugal', 'sector_educativo', 'lugar_nacimiento', 'afiliacion_salud'])
    ```
"""

# Eliminar filas que contengan NaN
data2 = data2.dropna(subset=['situacion_conyugal', 'sector_educativo', 'lugar_nacimiento', 'afiliacion_salud'])

"""- Después de eliminar filas, podes resetear el índice para que mantenga la secuencia:
    ```
    data = data.reset_index(drop=True)
    ```
"""

data2 = data2.reset_index(drop=True)

"""- Rellenar los datos faltantes para la columna `años_escolaridad`. Primero añadan la categoría `desconocido` y luego hacen un rellenado de los datos faltantes con `desconocido`."""

data2['años_escolaridad'] = (
    data2['años_escolaridad']
    .astype('category')
    .cat.add_categories(['desconocido'])
    .fillna('desconocido')
)

"""- Rellenar los datos faltantes para la columna `nivel_max_educativo` con `value=desconocido`"""

data2['nivel_max_educativo']=data2['nivel_max_educativo'].fillna(value="desconocido")

"""##Comparación con Respuesta Esperada 1"""

status(data2)

"""## 📍 Consigna 2

**_5) One hot encoding_**

- Hagan `data_ohe = pd.get_dummies(data)`
"""

data_ohe = pd.get_dummies(data2)

data_ohe.head()

data_ohe.columns

"""- Guardar `data_ohe` en un archivo pickle como vimos en clase con el nombre `categories_ohe.pickle`."""

import pickle

with open('categories_ohe.pickle', 'wb') as handle:
    pickle.dump(data_ohe.columns, handle, protocol=pickle.HIGHEST_PROTOCOL)

"""- Carguen el dataset `new_data = pd.read_csv("new_data.csv", sep=',')`"""

!gdown --id 1rJcEV0YP-nTRmxziBB9417F-dIKdFCl2 -O new_data.csv
new_data= pd.read_csv("new_data.csv", sep=',')

"""- A `new_data` hagan un reindex con las columnas que guardaron el archivo pickle y para los valores `NaN` rellenenlos con un `0`."""

with open('categories_ohe.pickle', 'rb') as handle:
    ohe_tr = pickle.load(handle)

ohe_tr

d_tr_ohe_2 = pd.get_dummies(new_data).reindex(columns = ohe_tr).fillna("0")

"""##Comparación Respuesta Esperada 2"""

d_tr_ohe_2

"""## 📍 Consigna 3

Cargar su notebook y datasets a un repositorio público personal y compartirlo por Discord.
<br>Consideren usar git lfs para los dataset con extensión csv.
"""

